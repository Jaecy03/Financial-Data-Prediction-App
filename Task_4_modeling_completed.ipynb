{"cells":[{"cell_type":"markdown","metadata":{"id":"c4noH7q4USKQ"},"source":["# Feature Engineering and Modelling\n","\n","---\n","\n","1. Import packages\n","2. Load data\n","3. Modelling\n","4. Evaluation and Interpretation\n","\n","---\n","\n","## 1. Import packages"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NwE6osQpUSKS"},"outputs":[],"source":["import warnings\n","warnings.filterwarnings(\"ignore\", category=FutureWarning)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cm3WmjAZUSKT"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import seaborn as sns\n","from datetime import datetime\n","import matplotlib.pyplot as plt\n","\n","# Shows plots in jupyter notebook\n","%matplotlib inline\n","\n","# Set plot style\n","sns.set(color_codes=True)"]},{"cell_type":"markdown","metadata":{"id":"sewogUFaUSKU"},"source":["---\n","## 2. Load data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oaIJfXJjUSKU"},"outputs":[],"source":["df = pd.read_csv('./data_for_predictions.csv')\n","# Remove the unnamed index column if it exists\n","if 'Unnamed: 0' in df.columns:\n","    df.drop(columns=[\"Unnamed: 0\"], inplace=True)\n","df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Check the distribution of the target variable\n","print(f\"Churn distribution:\\n{df['churn'].value_counts()}\")\n","print(f\"Churn rate: {df['churn'].mean():.2%}\")\n","\n","# Visualize the class distribution\n","plt.figure(figsize=(8, 6))\n","sns.countplot(x='churn', data=df)\n","plt.title('Distribution of Churn')\n","plt.xlabel('Churn (0 = No, 1 = Yes)')\n","plt.ylabel('Count')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"N2gjvbtCUSKV"},"source":["---\n","\n","## 3. Modelling\n","\n","We now have a dataset containing features that we have engineered and we are ready to start training a predictive model. Remember, we only need to focus on training a `Random Forest` classifier."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cPHZWHC8USKV"},"outputs":[],"source":["from sklearn import metrics\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n","from sklearn.metrics import confusion_matrix, classification_report, roc_curve, precision_recall_curve"]},{"cell_type":"markdown","metadata":{"id":"PitUvSFhUSKV"},"source":["### Data sampling\n","\n","The first thing we want to do is split our dataset into training and test samples. The reason why we do this, is so that we can simulate a real life situation by generating predictions for our test sample, without showing the predictive model these data points. This gives us the ability to see how well our model is able to generalise to new data, which is critical.\n","\n","A typical % to dedicate to testing is between 20-30, for this example we will use a 75-25% split between train and test respectively."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dstIVhBnUSKW"},"outputs":[],"source":["# Make a copy of our data\n","train_df = df.copy()\n","\n","# Separate target variable from independent variables\n","y = df['churn']\n","X = df.drop(columns=['id', 'churn'])\n","print(X.shape)\n","print(y.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ifim4p1WUSKW"},"outputs":[],"source":["X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n","print(X_train.shape)\n","print(y_train.shape)\n","print(X_test.shape)\n","print(y_test.shape)"]},{"cell_type":"markdown","metadata":{"id":"22A_oe_PUSKX"},"source":["### Model training\n","\n","Once again, we are using a `Random Forest` classifier in this example. A Random Forest sits within the category of `ensemble` algorithms because internally the `Forest` refers to a collection of `Decision Trees` which are tree-based learning algorithms. As the data scientist, you can control how large the forest is (that is, how many decision trees you want to include).\n","\n","The reason why an `ensemble` algorithm is powerful is because of the laws of averaging, weak learners and the central limit theorem. If we take a single decision tree and give it a sample of data and some parameters, it will learn patterns from the data. It may be overfit or it may be underfit, but that is now our only hope, that single algorithm. \n","\n","With `ensemble` methods, instead of banking on 1 single trained model, we can train 1000's of decision trees, all using different splits of the data and learning different patterns. It would be like asking 1000 people to all learn how to code. You would end up with 1000 people with different answers, methods and styles! The weak learner notion applies here too, it has been found that if you train your learners not to overfit, but to learn weak patterns within the data and you have a lot of these weak learners, together they come together to form a highly predictive pool of knowledge! This is a real life application of many brains are better than 1.\n","\n","Now instead of relying on 1 single decision tree for prediction, the random forest puts it to the overall views of the entire collection of decision trees. Some ensemble algorithms using a voting approach to decide which prediction is best, others using averaging. \n","\n","As we increase the number of learners, the idea is that the random forest's performance should converge to its best possible solution.\n","\n","Some additional advantages of the random forest classifier include:\n","\n","- The random forest uses a rule-based approach instead of a distance calculation and so features do not need to be scaled\n","- It is able to handle non-linear parameters better than linear based models\n","\n","On the flip side, some disadvantages of the random forest classifier include:\n","\n","- The computational power needed to train a random forest on a large dataset is high, since we need to build a whole ensemble of estimators.\n","- Training time can be longer due to the increased complexity and size of thee ensemble"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"km_R7pYnUSKX"},"outputs":[],"source":["# Train the Random Forest model with optimized parameters\n","# n_estimators: Number of trees in the forest\n","# max_depth: Maximum depth of the trees (helps prevent overfitting)\n","# min_samples_split: Minimum samples required to split an internal node\n","# min_samples_leaf: Minimum samples required to be at a leaf node\n","# random_state: For reproducibility\n","# class_weight: To handle class imbalance if present\n","\n","model = RandomForestClassifier(\n","    n_estimators=100,\n","    max_depth=15,\n","    min_samples_split=10,\n","    min_samples_leaf=4,\n","    random_state=42,\n","    class_weight='balanced',\n","    n_jobs=-1  # Use all available cores\n",")\n","\n","# Fit the model on the training data\n","model.fit(X_train, y_train)\n","\n","# Print training completion message\n","print(\"Random Forest model training completed!\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Feature importance analysis\n","feature_importances = pd.DataFrame({\n","    'Feature': X_train.columns,\n","    'Importance': model.feature_importances_\n","})\n","\n","# Sort by importance\n","feature_importances = feature_importances.sort_values('Importance', ascending=False).reset_index(drop=True)\n","\n","# Display top 15 most important features\n","plt.figure(figsize=(12, 8))\n","sns.barplot(x='Importance', y='Feature', data=feature_importances.head(15))\n","plt.title('Top 15 Feature Importances in Random Forest Model')\n","plt.tight_layout()\n","plt.show()\n","\n","# Print top 15 features\n","print(\"Top 15 most important features:\")\n","print(feature_importances.head(15))"]},{"cell_type":"markdown","metadata":{"id":"bwueFNNZUSKY"},"source":["### Evaluation\n","\n","Now let's evaluate how well this trained model is able to predict the values of the test dataset."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ncDbDAcJUSKY"},"outputs":[],"source":["# Generate predictions on the test set\n","y_pred = model.predict(X_test)  # Class predictions (0 or 1)\n","y_pred_proba = model.predict_proba(X_test)[:, 1]  # Probability predictions for the positive class (1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KRXNkqQYUSKY"},"outputs":[],"source":["# Calculate performance metrics\n","accuracy = accuracy_score(y_test, y_pred)\n","precision = precision_score(y_test, y_pred)\n","recall = recall_score(y_test, y_pred)\n","f1 = f1_score(y_test, y_pred)\n","roc_auc = roc_auc_score(y_test, y_pred_proba)\n","\n","# Print the metrics\n","print(f\"Accuracy: {accuracy:.4f}\")\n","print(f\"Precision: {precision:.4f}\")\n","print(f\"Recall: {recall:.4f}\")\n","print(f\"F1 Score: {f1:.4f}\")\n","print(f\"ROC AUC: {roc_auc:.4f}\")\n","\n","# Display the confusion matrix\n","cm = confusion_matrix(y_test, y_pred)\n","plt.figure(figsize=(8, 6))\n","sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n","            xticklabels=['Not Churned (0)', 'Churned (1)'],\n","            yticklabels=['Not Churned (0)', 'Churned (1)'])\n","plt.xlabel('Predicted')\n","plt.ylabel('Actual')\n","plt.title('Confusion Matrix')\n","plt.show()\n","\n","# Display the classification report\n","print(\"\\nClassification Report:\")\n","print(classification_report(y_test, y_pred))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Plot ROC curve\n","fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n","plt.figure(figsize=(10, 8))\n","plt.plot(fpr, tpr, label=f'ROC Curve (AUC = {roc_auc:.4f})')\n","plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n","plt.xlabel('False Positive Rate')\n","plt.ylabel('True Positive Rate')\n","plt.title('Receiver Operating Characteristic (ROC) Curve')\n","plt.legend(loc='lower right')\n","plt.grid(True, alpha=0.3)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Plot Precision-Recall curve\n","precision_curve, recall_curve, _ = precision_recall_curve(y_test, y_pred_proba)\n","plt.figure(figsize=(10, 8))\n","plt.plot(recall_curve, precision_curve, label=f'Precision-Recall Curve')\n","plt.xlabel('Recall')\n","plt.ylabel('Precision')\n","plt.title('Precision-Recall Curve')\n","plt.grid(True, alpha=0.3)\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["## 4. Evaluation Metrics Explanation and Model Performance Assessment\n","\n","### Why I Chose These Evaluation Metrics\n","\n","I selected multiple evaluation metrics to provide a comprehensive assessment of the model's performance:\n","\n","1. **Accuracy**: I included accuracy as it gives an overall view of correct predictions. However, accuracy alone can be misleading in imbalanced datasets where one class (typically non-churn) dominates. If 90% of customers don't churn, a model could achieve 90% accuracy by simply predicting \"no churn\" for everyone.\n","\n","2. **Precision**: This metric answers the question: \"Of all customers we predicted would churn, what percentage actually churned?\" High precision is important when the cost of false positives is high. In a churn context, this might relate to the cost of retention offers given to customers who wouldn't have churned anyway.\n","\n","3. **Recall**: This metric answers: \"Of all customers who actually churned, what percentage did we correctly identify?\" High recall is crucial when the cost of false negatives is high. In churn prediction, missing customers who will churn (false negatives) is typically more costly than incorrectly flagging loyal customers (false positives).\n","\n","4. **F1 Score**: As the harmonic mean of precision and recall, F1 score provides a balance between these two metrics. This is particularly valuable in churn prediction where we need to balance identifying as many churners as possible while minimizing false alarms.\n","\n","5. **ROC-AUC**: This metric evaluates how well the model can distinguish between classes across various threshold settings. It's threshold-independent, making it useful for comparing model performance regardless of the specific classification threshold chosen.\n","\n","6. **Confusion Matrix**: This visual representation helps understand the types of errors the model is making (false positives vs. false negatives), which is crucial for business decision-making in churn prevention.\n","\n","7. **Precision-Recall Curve**: This visualization is particularly useful for imbalanced datasets as it focuses on the positive class (churners) and shows the trade-off between precision and recall at different thresholds.\n","\n","### Assessment of Model Performance\n","\n","Based on the evaluation metrics, I can assess whether the model performance is satisfactory:\n","\n","1. **Contextual Evaluation**: The model should be evaluated in the context of the business problem. For churn prediction, even modest improvements over random guessing can translate to significant business value if the cost of churn is high.\n","\n","2. **Baseline Comparison**: The model should perform significantly better than simple baselines. The ROC curve comparison against the random guess line (diagonal) helps visualize this improvement.\n","\n","3. **Business Impact**: A good model for churn prediction should have high recall (to catch most potential churners) while maintaining reasonable precision (to avoid wasting resources on false alarms). The F1 score helps balance these concerns.\n","\n","4. **Class Imbalance Consideration**: Given that churn datasets are typically imbalanced, the model's ability to correctly identify the minority class (churners) is particularly important. The precision-recall curve helps assess this capability.\n","\n","5. **Feature Importance Analysis**: Understanding which features drive the predictions helps validate the model from a business perspective. If the important features align with business intuition about churn drivers, it increases confidence in the model.\n","\n","Overall, I would consider the model satisfactory if:\n","- The ROC-AUC is significantly above 0.5 (random guessing)\n","- The recall for the churn class is high enough to identify a meaningful proportion of potential churners\n","- The precision is sufficient to ensure that retention efforts are not wasted on too many false positives\n","- The model's predictions make business sense when examining feature importances\n","\n","The final assessment would depend on the specific results obtained after running the model, but the framework above provides a structured approach to evaluating its performance."]},{"cell_type":"markdown","metadata":{},"source":["## Conclusion\n","\n","In this notebook, we've built a Random Forest classifier to predict customer churn. We've evaluated its performance using multiple metrics and visualizations to gain a comprehensive understanding of its strengths and limitations.\n","\n","The Random Forest model is particularly well-suited for churn prediction because:\n","1. It can capture non-linear relationships between features and churn\n","2. It provides feature importance rankings that offer business insights\n","3. It can handle a mix of numerical and categorical features without extensive preprocessing\n","4. It's relatively robust to outliers and noisy data\n","\n","For future improvements, we could consider:\n","1. Hyperparameter tuning using cross-validation\n","2. Exploring other ensemble methods like Gradient Boosting\n","3. Feature engineering to create more predictive variables\n","4. Addressing class imbalance through techniques like SMOTE if necessary\n","5. Calibrating the model's probability outputs for better threshold selection\n","\n","The ultimate success of a churn prediction model should be measured by its impact on reducing customer attrition when deployed in a real business context."]}],"metadata":{"interpreter":{"hash":"152bf6e7dc8ee53edb5af21dc1a8faeab7f134840808a94079ed98d91ece7e0c"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.9"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}
